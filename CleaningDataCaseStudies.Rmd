# Importing & Cleaning Data in R: Case Studies
***
Notes taken during/inspired by the Datacamp course 'Importing & Cleaning Data in R: Case Studies' by Nick Carchedi.

## Ticket Sales Data

```{r}

# Import sales.csv: sales
sales <- read.csv("https://assets.datacamp.com/production/course_1294/datasets/sales.csv", stringsAsFactors = FALSE)

# View dimensions of sales
dim(sales)

# Inspect first 6 rows of sales
head(sales, n = 6)

# View column names of sales
names(sales)


```

Luckily, the rows and columns appear to be arranged in a meaningful way: each row represents an observation and each column a variable, or piece of information about that observation.

In R, there are a great many tools at your disposal to help get a feel for your data. Besides the three you used in the previous exercise, the functions str() and summary() can be very helpful.

The dplyr package, introduced in Cleaning Data in R, offers the glimpse() function, which can also be used for this purpose. The package is already installed on DataCamp; you just need to load it.

```{r}
# Look at structure of sales
str(sales)

# View a summary of sales
summary(sales)

# Load dplyr
library(dplyr)

# Get a glimpse of sales
glimpse(sales)
```

### Removing redundant info

The first column of data is just a duplication of the row numbers. Not very useful. Go ahead and delete that column.

Remember that nrow() and ncol() return the number of rows and columns in a data frame, respectively.

Also, recall that you can use square brackets to subset a data frame as follows:

> my_df[1:5, ]      # First 5 rows of my_df

> my_df[, 4]        # Fourth column of my_df

Alternatively, you can remove rows and columns using negative indices. For example:

> my_df[-(1:5), ]   # Omit first 5 rows of my_df

> my_df[, -4]       # Omit fourth column of my_df

```{r}
# Remove the first column of sales: sales2
sales2 <- sales[, -1]
```

Many of the columns have information that's of no use to us. For example, the first four columns contain internal codes representing particular events. The last fifteen columns also aren't worth keeping; there are too many missing values to make them worthwhile.

An easy way to get rid of unnecessary columns is to create a vector containing the column indices you want to keep, then subset the data based on that vector using single bracket subsetting.

```{r}
# Define a vector of column indices: keep
keep <- c(5:30)

# Subset sales2 using keep: sales3
sales3 <- sales2[keep]
```

Some of the columns in your data frame include multiple pieces of information that should be in separate columns. In this exercise, you will separate such a column into two: one for date and one for time. You will use the separate() function from the tidyr package (already installed for you).

For isntance the event_date_time column has a date and time separated by a space. Therefore, you'll use sep = " " as an argument to separate().
  
```{r}
head(sales3$event_date_time)
head(sales3$sales_ord_create_dttm)

# Load tidyr
library(tidyr)

# Split event_date_time: sales4
sales4 <- separate(sales3, event_date_time,
                   into = c("event_dt", "event_time"), sep = " ")
```

Looks like that second call to separate() threw a warning. Not to worry; warnings aren't as bad as error messages. It's not saying that the command didn't execute; it's just a heads-up that something unusual happened.

The warning says Too few values at 4 locations. You may be able to guess already what the issue is, but it's still good to take a look.

```{r}
sales3$sales_ord_create_dttm[c(2516, 3863, 4082, 4183)]

# Define an issues vector
issues <- c(2516, 3863, 4082, 4183)

# Print values of sales_ord_create_dttm at these indices
sales3$sales_ord_create_dttm[issues]

# Print a well-behaved value of sales_ord_create_dttm
sales3$sales_ord_create_dttm[2517]
```

## Working with dates

Some of the columns in your dataset contain dates of different events. Right now, they are stored as character strings. That's fine if all you want to do is look up the date associated with an event, but if you want to do any comparisons or math with the dates, it's MUCH easier to store them as Date objects.

Luckily, all of the date columns in this dataset have the substring "dt" in their name, so you can use the str_detect() function of the stringr package to find the date columns. Then you can coerce them to Date objects using a function from the lubridate package.

You'll use lapply() to apply the appropriate lubridate function to all of the columns that contain dates. Recall the following syntax for lapply() applied to some data frame columns of interest:

> lapply(my_data_frame[, cols], function_name)

Also recall that function names in lubridate combine the letters y, m, d, h, m, and s depending on the format of the date/time string being read in.

```{r}
# Load stringr
library(stringr)

# Find columns of sales5 containing "dt": date_cols
date_cols <- str_detect(names(sales4),"dt")

# Load lubridate
library(lubridate)

# Coerce date columns into Date objects
sales4[, date_cols] <- lapply(sales4[, date_cols], ymd)
```

Some of the calls to ymd() caused a failure to parse warning. That's probably because of more missing data, but again, it's good to check to be sure.

```{r}
## stringr is loaded

# Find date columns (don't change)
date_cols <- str_detect(names(sales4), "dt")

# Create logical vectors indicating missing values (don't change)
missing <- lapply(sales4[, date_cols], is.na)

# Create a numerical vector that counts missing values: num_missing
num_missing <- sapply(missing, sum)

# Print num_missing
num_missing
```

The number of NAs in each column match the numbers from the warning messages, so missing data is the culprit. How to proceed depends on your desired analysis. If you really need complete sets of date/time information, you might delete the rows or columns containing NAs.

## MBTA Ridership Data

The Massachusetts Bay Transportation Authority ("MBTA" or just "the T" for short) manages America's oldest subway, as well as Greater Boston's commuter rail, ferry, and bus systems.

It's your first day on the job as the T's data analyst and you've been tasked with analyzing average ridership through time. You're in luck, because this chapter of the course will guide you through cleaning a set of MBTA ridership data!

The dataset is stored as an Excel spreadsheet called mbta.xlsx.  You'll use the read_excel() function from Hadley Wickham's readxl package to import it.

The first time you import a dataset, you might not know how many rows need to be skipped. In this case, the first row is a title (see this Excel screenshot), so you'll need to skip the first row. 

```{r}

# Load readxl
library(readxl)

# Import mbta.xlsx and skip first row: mbta
mbta <- read_excel("D:/CloudStation/Documents/2017/RData/mbta.xlsx", skip = 1)

# View the structure of mbta
str(mbta)

# View the first 6 rows of mbta
head(mbta, n = 6)

# View a summary of mbta
summary(mbta)

```

The data are organized with observations stored as columns rather than as rows.

First, though, you can address the missing data. All of the NA values are stored in the All Modes by Qtr row. This row really belongs in a different data frame; it is a quarterly average of weekday MBTA ridership. Since this dataset tracks monthly average ridership, you'll remove that row.

Similarly, the 7th row (Pct Chg / Yr) and the 11th row (TOTAL) are not really observations as much as they are analysis. Go ahead and remove the 7th and 11th rows as well.

The first column also needs to be removed because it's just listing the row numbers.

```{r}
# Remove rows 1, 7, and 11 of mbta: mbta2
keep <- !(mbta$mode %in% c('All Modes by Qtr', 'Pct Chg / Yr', 'TOTAL'))
mbta2 <- mbta[keep,]

# Remove the first column of mbta2: mbta3
mbta3 <- mbta2[,-1]
```

Our next problem is variables are stored in rows instead of columns. The different modes of transportation (commuter rail, bus, subway, ferry, ...) are variables, providing information about each month's average ridership. The months themselves are observations. You can tell which is which because as you go through time, the month changes, but the modes of transport offered by the T do not.

As is customary, you want to represent variables in columns rather than rows. The first step is to use the gather() function from the tidyr package, which will gather columns into key-value pairs.


```{r}
# Load tidyr
library(tidyr)

# Gather columns of mbta3: mbta4
mbta4 <- gather(mbta3, month, thou_riders, -mode)

# View the head of mbta4
head(mbta4)
```

The thousand riders coloumn is still charecter data, so lets change that.

```{r}
# Coerce thou_riders to numeric
mbta4$thou_riders <- as.numeric(mbta4$thou_riders)
```

Now, you can finish the job you started earlier: getting variables into columns. Right now, variables are stored as "keys" in the mode column. You'll use the tidyr function spread() to make them into columns containing average weekday ridership for the given month and mode of transport.

```{r}
# Spread the contents of mbta4: mbta5
mbta5 <- spread(mbta4, mode, thou_riders)

# View the head of mbta5
head(mbta5)
```

If we want to look at the data by year, we can seperate the month field out in to month and year.

```{r}
# View the head of mbta5
head(mbta5)

# Split month column into month and year: mbta6
mbta6 <- separate(mbta5, month, into = c("month", "year"), sep ="-")

# View the head of mbta6
head(mbta6)
```

Looks like some of the data might be a bit out, which you can check using different functions, histogram being one such function.

```{r}
# View a summary of mbta6
summary(mbta6)

# Generate a histogram of Boat ridership
hist(mbta6$Boat)
```

Looks like we may have an input or typo on the value close to 40 - perhaps should have been a 4.0 or just a 4.  Because it's an error, you don't want this value influencing your analysis. In this exercise, you'll locate the incorrect value and change it to 4.

```{r}
# Find the row number of the incorrect value: i
i <- which(mbta6$Boat == 40)

# Replace the incorrect value with 4
mbta6$Boat[i] <- 4

# Generate a histogram of Boat column
hist(mbta6$Boat)

library(ggplot2)


# Look at all T ridership over time (example plot)
ggplot(mbta4, aes(x = month, y = thou_riders, col = mode)) + geom_point() + 
  scale_x_discrete(name = "Month", breaks = c(200701, 200801, 200901, 201001, 201101)) +  
  scale_y_continuous(name = "Avg Weekday Ridership (thousands)")
```


## World Food Facts

```{r}
library(data.table)

# Import sales.csv: food
food <- fread("https://assets.datacamp.com/production/course_1294/datasets/food.csv", stringsAsFactors = FALSE)

# Convert food to a data frame
food <- data.frame(food)

# View summary of food
summary(food)

# View head of food
head(food)

# View structure of food
str(food)

```

This is a large dataset and it is difficult to see what is going on.  So let's try dplyr. 

```{r}
# Load dplyr
library(dplyr)

# View a glimpse of food
glimpse(food)

# View column names of food
names(food)
```

There is a lot of information there, there's some information on what and when information was added (1:9), meta information about food (10:17, 22:27), where it came from (18:21, 28:34), what it's made of (35:52), nutrition grades (53:54), some unclear (55:63), and some nutritional information (64:159).  

There are also some duplicates, different pairs of columns that contain duplicate information.   There are many columns containing information that you just can't use.

```{r}
# Define vector of duplicate cols 
duplicates <- c(4, 6, 11, 13, 15, 17, 18, 20, 22, 
                24, 25, 28, 32, 34, 36, 38, 40, 
                44, 46, 48, 51, 54, 65, 158)

# Remove duplicates from food: food2
food2 <- food[, -duplicates]

# Define useless vector 
useless <- c(1, 2, 3, 32:41)

# Remove useless columns from food2: food3
food3 <- food2[, -useless]

```

Earlier on we saw that there are many columns containing nutritional information in them, identified with a '100g' label in the column name.  If we want to use the nutritional information, we can therefore use this to identify those columns.

```{r}
library(stringr)

# Create vector of column indices: nutrition
nutrition <- str_detect(names(food3), "100g")

# View the number of columns it applies to
summary(nutrition)

# View a summary of nutrition columns
summary(food3[, nutrition])
```

We can see there are a large number of missing (NA) values.  For some variables however, NA is sometimes left as the default where the actual number is zero.  This is the case with the sugars_100g column.

```{r}
# Find indices of sugar NA values: missing
missing <- is.na(food3$sugars_100g)

# Replace NA values with 0
food3$sugars_100g[missing] <- 0

# Create first histogram
hist(food3$sugars_100g, breaks = 100)

# Create food4
food4 <- food3[food3$sugars_100g != 0, ]

# Create second histogram
hist(food4$sugars_100g, breaks = 100)
```

Your dataset has information about packaging, but there's a bit of a problem: it's stored in several different languages (Spanish, French, and English). 

The root word for plastic is same in English (plastic), French (plastique), and Spanish (plastico). To get a general idea of how many of these foods are packaged in plastic, you can look through the packaging_tags column for the string "plasti".

```{r}
# Find entries containing "plasti": plastic
plastic <- str_detect(food3$packaging_tags, "plasti")

# Print the sum of plastic
sum(plastic)
```

## School Attendance Data

In this section we will work with attendance data from public schools in the US, organized by school level and state, during the 2007-2008 academic year. The data contain information on average daily attendance (ADA) as a percentage of total enrollment, school day length, and school year length.

```{r, message = FALSE}
# Load the gdata package
library(gdata)

# Import the spreadsheet: att.  NOTE: Requires perl to be installed
url <- 'http://s3.amazonaws.com/assets.datacamp.com/production/course_1294/datasets/attendance.xls'
att <- read.xls(url)

# Print the column names 
names(att)

# Print the first 6 rows
head(att)

# Print the last 6 rows
tail(att)

# Print the structure
str(att)
```

In the table there is some metadata placed at the bottom of the table, we can remove this.  Also some of the columns don't contain attendance figures, they contain daily hours in the even odd number columns 3-17, so we can remove these too.

```{r}
# Create remove for the rows
remove <- c(3,56:59)

# Create att2
att2 <- att[-remove, ]

# Create remove for the odd columns
remove <- seq(3,17,2)

# Create att3
att3 <- att2[, -remove]

```

In this data frame, columns 1, 6, and 7 represent attendance data for US elementary schools, columns 1, 8, and 9 represent data for secondary schools, and columns 1 through 5 represent data for all schools in the US.  Each of these should be stored as its own separate data frame and split accordingly.

```{r}
# Subset just elementary schools: att_elem
att_elem <- att3[,c(1,6,7)]

# Subset just secondary schools: att_sec
att_sec <- att3[,c(1,8,9)]

# Subset all schools: att4
att4 <- att3[,1:5]
```

Next we can assign column names to the variables, then remove the now un-neccessary first two columns

```{r}
# Define cnames vector 
cnames <- c("state", "avg_attend_pct", "avg_hr_per_day", 
            "avg_day_per_yr", "avg_hr_per_yr")

# Assign column names of att4
colnames(att4) <- cnames

# Remove first two rows of att4: att5
att5 <- att4[-c(1,2), ]

# View the names of att5
names(att5)
```

Next the state variable has periods (.) for spaces and trailing charecters to pad the length for the field.  We can tidy this up.

```{r}
# View the head of att5
head(att5)

# Remove all periods in state column
att5$state <- str_replace_all(att5$state, "\\.", "")

# Remove white space around state names
att5$state <- str_trim(att5$state)

# View the head of att5
head(att5)
```

Looking at the first few lines we can see that some of the data types are incorrect - upon import, numerical data has come in as character strings and is currently as factor variables.

```{r}
# View the structure
str(att5)

# Change columns to numeric using dplyr (one way to acheive numeric conversion)
library(dplyr)
example <- mutate_at(att5, c(2:5), funs(as.numeric))

# Define vector containing numerical columns: cols
cols <- c(2:5)

# Use sapply to coerce cols to numeric (another way to convert)
att5[, cols] <- sapply(att5[,cols], as.numeric)

# View the structure
str(att5)
  
```

